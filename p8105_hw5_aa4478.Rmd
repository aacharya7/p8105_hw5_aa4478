---
title: Homework 5 Iteration
author: "Ayeshra Acharya"
date: "11/18/2020"
output: github_document
---


```{r setup, include=FALSE}
library(tidyverse)
library(rvest)
knitr::opts_chunk$set(
	fig.width = 6, 
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```
## Problem 1 - Homicides in 50 Large U.S. Cities
### Read in and clean data

```{r cars}
homicide_df = 
  read.csv("./data/homicide-data.csv") %>%
  mutate(
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest" ~ "unsolved",
      disposition == "Closed by arrest" ~ "solved"
    ),
    city_state = str_c(city,state,sep = "_")
  ) %>%
  select(city_state, resolved) %>%
  filter(city_state !="Tulsa AL")
```

### Aggregate
```{r}
aggregate_df = 
  homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    hom_total = n(),
    hom_unsolved = sum(resolved == "unsolved")
  )
```
### Prop Test for Baltimore
```{r}
prop.test(
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_unsolved),
    aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_total)) %>% 
  broom::tidy()
```

### Iteration All Cities
```{r}
results_df = 
  aggregate_df %>% 
  mutate(
     prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y)),
     tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
   ) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_tests) %>% 
  select(city_state, estimate, conf.low, conf.high)
```
```{r}
results_df %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

## Problem 2 - Longitudional Study
```{r}
data_1 = read_csv("long_data/con_01.csv")
```
### Tidying data
```{r, message = FALSE}
path_df = 
  tibble(
    path = list.files("long_data")
  ) %>% 
  mutate(
    path = str_c("long_data/", path),
    data = map(path, read_csv)) %>% 
  unnest(data) %>%
  separate(path, into = c("folder", "arm"), sep = 9) %>%
  separate(arm, into = c("arm", "id"), sep = "_") %>% 
  separate(id, into = c("id", "na"), sep = 2) %>% 
  select(-folder, -na) %>% 
  pivot_longer(
    week_1:week_8,
    names_to = "week", 
    values_to = "observation",
    names_prefix = "week_"
  ) %>%
  mutate(
    id = str_remove(id, "^0+"),
    week = as.numeric(week),
    subject_id = str_c(arm, id, sep = "_")
    ) %>% 
  select(-id)

path_df
```

### Creating spaghetti plot
```{r, message = FALSE}
path_df %>% 
  ggplot(aes(x = week, y = observation, color = arm, group = subject_id)) +
  geom_path() +
  labs(
    title = "Observations for subject over time",
    x = "Week", 
    y = "Observation"
  )
```
This graph shows us that the subjects in the experimental arm had more observations than subjects in the control arm. 
In the beginning of the study, the observations are more similar between the experimental and control, and as the weeks go on, they diverge. Also, it appears that the observations for the experimental arm are decreasing over time, 


## Problem 3 - False Null Hypothesis 

### T-test function
```{r}
t_test = function(sample_size = 30, mu, sigma = 5) {
  simulation = 
    tibble(x = rnorm(n = sample_size, mean = mu, sd = sigma))
  simulation %>% 
  t.test() %>% 
  broom::tidy()
}
```
### Setting mu = 0 
```{r}
sim_results = 
  rerun(5000, t_test(mu = 0)) %>% 
  bind_rows()
sim_results %>% 
  select(estimate, p.value)
```
### Repeating above for 1-6
```{r}
rep_sim = 
  tibble(mean = c(0, 1, 2, 3, 4, 5, 6)) %>% 
  mutate(
    output_lists = map(.x = mean, ~rerun(5000, t_test(mu = .x))),
    estimate_dfs = map(output_lists, bind_rows)) %>% 
  select(-output_lists) %>% 
  unnest(estimate_dfs)
rep_sim %>% 
  select(mean, estimate, p.value)
```
### Plot of proportion of times the null was rejected 

